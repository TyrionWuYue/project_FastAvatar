<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">FastAvatar: Towards Unified Fast High-Fidelity 3D Avatar Reconstruction with Large Gaussian Reconstruction Transformers</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://tyrionwuyue.github.io/" target="_blank">Yue Wu</a><sup>1,2</sup>,</span>
              
              <span class="author-block">
                    <a href="https://github.com/EavianWoo" target="_blank">Yufan Wu</a><sup>3,4</sup>,</span>

              <span class="author-block">
                    <a href="https://scholar.google.com/citations?hl=zh-CN&user=__nVVTcAAAAJ&view_op=list_works&gmla=AH8HC4wvSb3GOijD2yVOgTTZZpBYfwZv7gccn3wsBOGSLX6yGYuTg2bXKKld9Lc53lj0jO7WwL-7e-gCE33w5sPjKyvRjTmGUrS3fAWAv5A" target="_blank">Wen Li</a><sup>3,4</sup>,</span>
              
              <span class="author-block">
                    <a href="https://orcid.org/0000-0003-1205-3524" target="_blank">Yuxi Lu</a><sup>1</sup>,</span>
              
              <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=4N5hE8YAAAAJ&hl=en" target="_blank">Kairui Feng</a><sup>1,2*</sup>,</span>
              
              <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=UuCqlfEAAAAJ&hl=en" target="_blank">Xuanhong Chen</a><sup>3*</sup>,</span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                        <sup>1</sup>Tongji University, 
                        <sup>2</sup>Shanghai Innovation Institute, 
                        <sup>3</sup>Shanghai Jiao Tong University, 
                        <sup>4</sup>Akool Research
                    </span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding authors</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper (Coming Soon)</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/TyrionWuYue/FastAvatar" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                  </a>
                </span> -->

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/teaser/teaser.png" alt="Teaser Image" id="tree" style="width: 100%; height: auto; max-height: 100%;">
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Despite significant progress in 3D avatar reconstruction, it still faces challenges such as high time complexity, sensitivity to data quality, and low data utilization.
            We propose <strong>FastAvatar</strong>, a feedforward 3D avatar framework capable of flexibly leveraging diverse daily recordings (e.g., a single image, multi-view observations, or monocular video) to reconstruct a high-quality 3D Gaussian Splatting (3DGS) model within seconds, using only a single unified model.
            FastAvatarâ€™s core is a Large Gaussian Reconstruction Transformer featuring three key designs:
            First, a variant VGGT-style transformer architecture aggregating multi-frame cues while injecting initial 3D prompt to predict an aggregatable canonical 3DGS representation;
            Second, multi-granular guidance encoding (camera pose, FLAME expression, head pose) mitigating animation-induced misalignment for variable-length inputs;
            Third, incremental Gaussian aggregation via landmark tracking and sliced fusion losses.
            Integrating these features, FastAvatar enables incremental reconstruction, i.e., improving quality with more observations, unlike prior work wasting input data. 
            This yields a quality-speed-tunable paradigm for highly usable avatar modeling.
            Extensive experiments show that FastAvatar has higher quality and highly competitive speed compared to existing methods.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Method section -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
      </div>
    </div>
    
    <!-- Method image -->
    <div class="hero-body">
      <img src="static/method/framework.png" alt="Method Image" style="width: 100%; height: auto; max-height: 100%;">
      <!-- <h2 class="subtitle has-text-centered">
        Overview of FastAvatar's architecture and key components for unified 3D avatar reconstruction.
      </h2> -->
    </div>
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            FastAvatar is a feed-forward framework designed for high-quality, animatable <strong>3D Gaussian Splatting (3DGS) avatars</strong> reconstruction from <strong>variable-length input observations</strong> such as single images or multi-view video sequences. Unlike optimization-based methods, FastAvatar leverages a <strong>Large Gaussian Reconstruction Transformer (LGRT)</strong> architecture to efficiently achieve robust reconstruction fidelity while supporting dynamic facial expressions and poses.
          </p>
          <p>
            The pipeline can be summarized as follows:
          </p>
          <ul>
            <li>
              <strong>Facial Tokenization:</strong> Each input frame is processed into latent tokens via <strong>DINOv2</strong> for feature extraction. Tokens are encoded with expression coefficients, pose, and camera information to distinguish facial features across frames. Patchified tokens ensure compatibility with subsequent transformer-based processing.
            </li>
            <li>
              <strong>Attention-Based Aggregation:</strong> Tokens are fused using both <strong>frame attention</strong> (intra-frame processing via positional prompts) and <strong>global attention</strong> (cross-frame alignment). This enables accurate 3D spatial registration and consistency across variable-length inputs.
            </li>
            <li>
              <strong>Gaussian Splatting Prediction:</strong> Aggregated tokens are processed through an MLP-based <strong>GS Head</strong> to predict Gaussian splatting attributes such as scale, position, rotation, color, and opacity. These attributes are rasterized into a high-quality 3D Gaussian point cloud representation for animatable avatars.
            </li>
            <li>
              <strong>Canonical Fusion:</strong> Multi-view Gaussian splatting representations are fused into a canonical 3DGS model, guided by loss functions like <strong>Landmark Tracking Loss</strong> and <strong>Sliced Fusion Loss</strong> to ensure proper alignment and eliminate artifacts.
            </li>
            <li>
              <strong>Efficient Rendering:</strong> The reconstructed 3DGS avatar is driven by expression codes (e.g., derived from FLAME) for animatable facial movement control. Through activation caching, animation speeds of ~55 FPS (input 16 frames) can be achieved on an RTX 4090 GPU.
            </li>
          </ul>
        </div>
      </div>
    </div>

  </div>
</section>
<!-- End method section -->

<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Self-reenacted Results</h2>
      <div id="self-results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="self_video1" autoplay controls muted loop height="100%" preload="metadata">
            <source src="static/self_ren/001.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="self_video2" autoplay controls muted loop height="100%" preload="metadata">
            <source src="static/self_ren/002.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="self_video3" autoplay controls muted loop height="100%" preload="metadata">
            <source src="static/self_ren/003.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video4">
          <video poster="" id="self_video4" autoplay controls muted loop height="100%" preload="metadata">
            <source src="static/self_ren/004.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video5">
          <video poster="" id="self_video5" autoplay controls muted loop height="100%" preload="metadata">
            <source src="static/self_ren/005.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Cross-reenacted Results</h2>
      <div id="cross-results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="cross_video1" autoplay controls muted loop height="100%" preload="metadata">
            <source src="static/cross_ren/001.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="cross_video2" autoplay controls muted loop height="100%" preload="metadata">
            <source src="static/cross_ren/002.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="cross_video3" autoplay controls muted loop height="100%" preload="metadata">
            <source src="static/cross_ren/003.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video4">
          <video poster="" id="cross_video4" autoplay controls muted loop height="100%" preload="metadata">
            <source src="static/cross_ren/004.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video5">
          <video poster="" id="cross_video5" autoplay controls muted loop height="100%" preload="metadata">
            <source src="static/cross_ren/005.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Multi-view & Incremental Reconstruction Results</h2>
      <div id="multi-results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="multi_video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/multi/001.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="multi_video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/multi/002.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->


<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
